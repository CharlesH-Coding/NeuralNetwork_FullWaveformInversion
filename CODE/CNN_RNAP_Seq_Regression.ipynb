{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'rnap_scanned_over_ecoli_genome200k.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bcfef15cc73e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0minput_data_ordered_raw\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rnap_scanned_over_ecoli_genome200k.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0msequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data_ordered_raw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'seq'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ObsPy_Base/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ObsPy_Base/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ObsPy_Base/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ObsPy_Base/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ObsPy_Base/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'rnap_scanned_over_ecoli_genome200k.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "input_data_ordered_raw =  pd.read_csv('rnap_scanned_over_ecoli_genome200k.csv')\n",
    "sequences = input_data_ordered_raw['seq'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_ordered_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unbalanced_pos_labels = np.array(input_data_ordered_raw['val'][0:100000])\n",
    "unbalanced_pos_labels = (unbalanced_pos_labels-min(unbalanced_pos_labels))/(max(unbalanced_pos_labels)-min(unbalanced_pos_labels))\n",
    "\n",
    "plt.hist(unbalanced_pos_labels,bins=100,label='Raw Training Data')\n",
    "plt.legend()\n",
    "plt.ylabel('Counts',fontsize=12)\n",
    "plt.xlabel('Values of Sequences (from MPAthic)',fontsize=12)\n",
    "#plt.title('Convolutional Neural Network Performance')\n",
    "plt.tight_layout()\n",
    "#\n",
    "#plt.savefig('Write_up/raw_data_histogram.png')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomly sample vals and seqs to prevent data imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_ordered_raw[['val','seq']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normally sample high value seqs more\n",
    "# https://stackoverflow.com/questions/33160367/numpy-how-to-generate-a-normally-distributed-set-of-integers\n",
    "bi = np.random.binomial(n=10000, p=0.5, size=1000)\n",
    "beta = np.random.beta(a=19,b=1,size=50000)\n",
    "myList = list(100000*beta)\n",
    "myList = [round(x) for x in myList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plt.hist(myList, bins=100)\n",
    "#plt.show()\n",
    "#np.random.seed(1)    # good seeds: 10,5,1\n",
    "# for larger data, seed 2,5 is okay.\n",
    "np.random.seed(6)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sample = 90000   # number of training samplesq\n",
    "test_size = 5000    # number of test samples\n",
    "\n",
    "\n",
    "#num_sample = 40000   # number of training samplesq\n",
    "#test_size = 1000    # number of test samples\n",
    "\n",
    "binomial_probability_parameter = 0.5\n",
    "\n",
    "index_random_sample_training_data = np.random.randint(num_sample,size=(num_sample))\n",
    "###index_random_sample_training_data = np.random.binomial(n=200000, p=binomial_probability_parameter, size=num_sample)\n",
    "\n",
    "#beta = np.random.beta(a=20,b=1,size=num_sample)\n",
    "#index_random_sample_training_data = list(100000*beta)\n",
    "#index_random_sample_training_data = [round(x) for x in index_random_sample_training_data]\n",
    "\n",
    "#index_random_sample_training_data = set(index_random_sample_training_data)\n",
    "#index_random_sample_training_data = list(index_random_sample_training_data)\n",
    "\n",
    "input_data_raw = input_data_ordered_raw[['val','seq']].loc[index_random_sample_training_data]\n",
    "print(input_data_raw.head())\n",
    "\n",
    "index_random_sample_test_data = np.random.randint(num_sample,size=(test_size))\n",
    "###index_random_sample_test_data = np.random.binomial(n=200000, p=binomial_probability_parameter, size=test_size)\n",
    "\n",
    "#beta_test = np.random.beta(a=20,b=1,size=test_size)\n",
    "#index_random_sample_test_data = list(100000*beta_test)\n",
    "#index_random_sample_test_data = [round(x) for x in index_random_sample_test_data]\n",
    "\n",
    "\n",
    "#index_random_sample_test_data = set(index_random_sample_test_data)\n",
    "#index_random_sample_test_data = list(index_random_sample_test_data)\n",
    "\n",
    "input_data_raw_test = input_data_ordered_raw[['val','seq']].loc[index_random_sample_test_data]\n",
    "\n",
    "print(input_data_raw_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from random import shuffle\n",
    "#shuffle(index_random_sample_training_data)\n",
    "#shuffle(index_random_sample_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#num_sample = len(set(index_random_sample_training_data))\n",
    "#test_size = len(set(index_random_sample_test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensure no test data got into training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_data_raw = input_data_raw[~input_data_raw.seq.isin(input_data_raw_test.seq)]\n",
    "#input_data_raw = input_data_raw.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_size = len(input_data_raw_test.drop_duplicates())\n",
    "test_size = len(input_data_raw_test)\n",
    "print(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#num_sample = len(input_data_raw.drop_duplicates())\n",
    "num_sample = len(input_data_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive and negative labels\n",
    "# normalize the following between 0 and 1\n",
    "pos_labels = np.array(input_data_raw['val'][0:num_sample])\n",
    "pos_labels = (pos_labels-min(pos_labels))/(max(pos_labels)-min(pos_labels))\n",
    "\n",
    "# test positive and negative labels\n",
    "test_pos_labels = np.array(input_data_raw_test['val'][0:test_size])\n",
    "test_pos_labels = (test_pos_labels-min(test_pos_labels))/(max(test_pos_labels)-min(test_pos_labels))\n",
    "\n",
    "#plt.hist(pos_labels,bins=50,label='Balanced Training Data')\n",
    "plt.hist(pos_labels,bins=100,label='Balanced Training Data')\n",
    "plt.legend()\n",
    "\n",
    "plt.ylabel('Counts',fontsize=12)\n",
    "plt.xlabel('Values of Sequences (from MPAthic)',fontsize=12)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('Write_up/balanced_training_histogram.png')\n",
    "plt.show()\n",
    "# assigned random values to negative examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(pos_labels,bins=50,label='Balanced Training Data')\n",
    "plt.hist(test_pos_labels,bins=100,label='Sampled Test Data')\n",
    "plt.legend()\n",
    "\n",
    "plt.ylabel('Counts',fontsize=12)\n",
    "plt.xlabel('Values of Sequences (from MPAthic)',fontsize=12)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('Write_up/balanced_training_histogram.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequences = np.array(sequences)\n",
    "\n",
    "pos = []\n",
    "#pos = list(sequences[index_random_sample_training_data])\n",
    "pos = list(input_data_raw['seq'])\n",
    "\n",
    "test_pos = []\n",
    "#test_pos = list(sequences[index_random_sample_test_data])\n",
    "test_pos = list(input_data_raw_test['seq'])\n",
    "\n",
    "pos = np.array(pos)\n",
    "test_pos = np.array(test_pos)\n",
    "\n",
    "seq_length = len(pos[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " input_data_raw_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pos_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp_pos = []\n",
    "temp_pos_test = []\n",
    "for reshape_index in range(len(pos)):\n",
    "    temp_pos.append(list(pos[reshape_index]))\n",
    "\n",
    "for reshape_test_index in range(len(test_pos)):\n",
    "    temp_pos_test.append(list(test_pos[reshape_test_index]))\n",
    "    \n",
    "pos = temp_pos\n",
    "test_pos = temp_pos_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos = np.array(pos)\n",
    "test_pos = np.array(test_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "riQRzV6CNp33",
    "outputId": "a27104ff-7917-4987-dccc-7780792beac2"
   },
   "outputs": [],
   "source": [
    "pos_tensor = np.zeros(list(pos.shape) + [4])\n",
    "test_pos_tensor = np.zeros(list(test_pos.shape) + [4])\n",
    "\n",
    "base_dict = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
    "\n",
    "#naive one-hot encoding\n",
    "for row in range(num_sample):\n",
    "    for col in range(seq_length):\n",
    "        pos_tensor[row,col,base_dict[pos[row,col]]] = 1\n",
    "        if(row<test_size):\n",
    "            test_pos_tensor[row,col,base_dict[test_pos[row,col]]] = 1\n",
    "\n",
    "#print('Positive sample matrix shape: {}'.format(pos.shape))\n",
    "# this should be a 3D tensor with shape: (samples, steps, input_dim)\n",
    "#print('Positive sample tensor shape: {}'.format(pos_tensor.shape))\n",
    "\n",
    "X = pos_tensor\n",
    "y = pos_labels\n",
    "\n",
    "X_test = test_pos_tensor\n",
    "y_test = test_pos_labels\n",
    "\n",
    "print('Training set shape: {}'.format(X.shape))\n",
    "print('Training set label shape: {}'.format(y.shape))\n",
    "\n",
    "print('Test set shape: {}'.format(X_test.shape))\n",
    "print('Test set label shape: {}'.format(y_test.shape))\n",
    "#print('\\nOne-hot encoding looks like:\\n {}'.format(X[0,0:10,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define error metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    from keras import backend\n",
    "    return backend.sqrt(backend.mean(backend.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "# coefficient of determination (R^2) for regression\n",
    "def r_square(y_true, y_pred):\n",
    "    from keras import backend as K\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return (1 - SS_res/(SS_tot + K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "bD1LpHUKNtVh",
    "outputId": "ec377700-10d7-44a3-c80b-45c2a7133a11"
   },
   "outputs": [],
   "source": [
    "#here comes the deep learning part\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Dense, Flatten, Dropout\n",
    "from keras.activations import relu\n",
    "from keras.layers.pooling import MaxPooling1D,GlobalMaxPool1D\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.initializers import TruncatedNormal,glorot_normal\n",
    "\n",
    "#sanity check for dimensions\n",
    "#print('Shape of the output of first layer: {}'.format(model.predict_on_batch(pos_tensor[0:1,:,:]).shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "2CkOlW_EN2gn",
    "outputId": "fbdf111b-fb35-4569-c9e3-34ead250e689",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "# padding same works\n",
    "#model.add(Conv1D(filters = 41, kernel_size=41, padding='same', input_shape=(seq_length, 4), activation='relu'))\n",
    "#model.add(Conv1D(41, 41, input_shape=(seq_length, 4),padding='same', activation='relu',kernel_initializer=glorot_normal(0)))\n",
    "model.add(Conv1D(10, 41, input_shape=(seq_length, 4),padding='same', activation='relu'))\n",
    "#model.add(MaxPooling1D(pool_size=2))\n",
    "#model.add(Conv1D(4, 10, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "#model.add(Conv1D(10, 4, input_shape=(seq_length, 4),padding='same', activation='relu'))\n",
    "#model.add(Conv1D(10, 10, activation='relu'))\n",
    "#model.add(MaxPooling1D(pool_size=4))\n",
    "#model.add(Conv1D(30, 15, padding='same', input_shape=(seq_length, 4), activation='relu'))\n",
    "#model.add(MaxPooling1D(pool_size=5))\n",
    "model.add(Flatten())\n",
    "#model.add(Dense(50, activation='relu'))\n",
    "#model.add(Dropout(0.25))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "#model.add(Dense(1, activation='relu'))\n",
    "\n",
    "sgd = SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "#model.compile(loss='mean_squared_error',optimizer='adam', metrics=['mean_squared_error',r_square])\n",
    "#model.compile(loss='mean_squared_error',optimizer=sgd, metrics=[rmse,r_square])\n",
    "#model.compile(loss='mean_squared_error',optimizer=Adam(lr=0.0001), metrics=[rmse,r_square])\n",
    "model.compile(loss='mean_squared_error',optimizer=Adam(lr=0.0001), metrics=['mean_squared_error'])\n",
    "\n",
    "#history = model.fit(X, y, validation_split=0.2, epochs=50)  # starts training\n",
    "history = model.fit(X, y, validation_split=0.2, epochs=20)  # starts training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "colab_type": "code",
    "id": "-VpzZqooOAPx",
    "outputId": "30d34bfd-b21e-47c7-9c64-d1cf407b23c6"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.rcParams[\"figure.figsize\"] = (5,5)\n",
    "plt.plot(history.history['loss'],color='blue')\n",
    "plt.plot(history.history['val_loss'],color='orange')\n",
    "plt.title('Model loss',fontsize=12)\n",
    "plt.ylabel('loss',fontsize=12)\n",
    "plt.xlabel('epoch',fontsize=12)\n",
    "plt.legend(['train', 'validation'])\n",
    "#plt.savefig('Write_up/model_loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "colab_type": "code",
    "id": "VeIdsrBEO49U",
    "outputId": "04003ed6-30d1-494a-da95-3672e19fb46d"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "plt.rcParams[\"figure.figsize\"] = (5,5)\n",
    "plt.plot(history.history['val_rmse'],color='orange')\n",
    "plt.plot(history.history['rmse'],color='b')\n",
    "plt.title('Model RMSE',fontsize=12)\n",
    "plt.ylabel('RMSE',fontsize=12)\n",
    "plt.xlabel('epoch',fontsize=12)\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.savefig('Write_up/RMSE_loss.png')\n",
    "plt.legend(['rmse', 'val_rmse'], loc='upper right')\n",
    "#plt.savefig('Write_up/rmse.png')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#plt.rcParams[\"figure.figsize\"] = (5,5)\n",
    "plt.plot(history.history['val_r_square'],color='b')\n",
    "plt.plot(history.history['r_square'],color='orange')\n",
    "plt.title('model R^2',fontsize=12)\n",
    "plt.ylabel('R^2',fontsize=12)\n",
    "plt.xlabel('epoch',fontsize=12)\n",
    "plt.legend(['r_sq', 'val_r_sq'], loc='lower right')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('Write_up/Rsquared.png')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vuJi3zO_OaMi",
    "outputId": "91f9168e-a49f-4c51-8a07-85d32e324e0b"
   },
   "outputs": [],
   "source": [
    "#have a look at the filter\n",
    "convlayer = model.layers[0]\n",
    "weights = convlayer.get_weights()[0].squeeze()\n",
    "print('Convolution parameter shape: {}'.format(weights.shape))\n",
    "\n",
    "num2seq = ['A','C','G','T']\n",
    "\n",
    "#''.join([num2seq[np.argmax(weights[i,:])] for i in range(weights.shape[0])])\n",
    "#test_pred = ''.join([num2seq[np.argmax(weights[i,:])] for i in range(weights.shape[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(test_pos_labels,bins=50,alpha=0.75,label='Test labels')\n",
    "plt.hist(model_prediction,bins=50,alpha=0.5,label='Model Predictions')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_model_prediction = model.predict(test_pos_tensor)\n",
    "#from pylab import rcParams\n",
    "#rcParams['xtick.labelsize'] = 15 \n",
    "#rcParams['ytick.labelsize'] = 15 \n",
    "#rcParams['figure.figsize'] = 6, 6\n",
    "\n",
    "plt.scatter(y_test,pos_model_prediction,s=20,alpha=0.5,color='red')\n",
    "plt.plot([0,1],alpha=0.35,linewidth=3,color='black')\n",
    "plt.ylabel('Neural network predictions of values',fontsize=15)\n",
    "plt.xlabel('Values from test set (from MPAthic)',fontsize=15)\n",
    "plt.title('Convnet Performance. Correlation: '+str(np.corrcoef(y_test,pos_model_prediction.flatten())[1,0]))\n",
    "plt.tight_layout()\n",
    "#plt.rcParams['axes.facecolor']='white'\n",
    "#plt.rcParams['savefig.facecolor']='white'\n",
    "#plt.savefig('prediction_vs_observed.png',facecolor=fig.get_facecolor(), transparent=True)\n",
    "#plt.savefig('prediction_vs_observed.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Saliency and Plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "K.set_session(tf.Session(graph=model.output.graph)) \n",
    "init = tf.global_variables_initializer() \n",
    "K.get_session().run(init)\n",
    "\n",
    "def compute_salient_bases(model, x):\n",
    "  input_tensors = [model.input]\n",
    "  gradients = model.optimizer.get_gradients(model.output[0][0], model.input)\n",
    "  \n",
    "  compute_gradients = K.function(inputs = input_tensors, outputs = gradients)\n",
    "  x_value = np.expand_dims(x, axis=0)\n",
    "\n",
    "  gradients = compute_gradients([x_value])[0][0]\n",
    "  sal = np.clip(np.sum(np.multiply(gradients,x), axis=1),a_min=0, a_max=None)\n",
    "  return sal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_index = model_prediction.argmax()\n",
    "sequence_index = 3000\n",
    "sal = compute_salient_bases(model, X_test[sequence_index])\n",
    "\n",
    "plt.figure(figsize=[16,5])\n",
    "barlist = plt.bar(np.arange(len(sal)), sal)\n",
    "#[barlist[i].set_color('C1') for i in range(5,17)]\n",
    "plt.xlabel('Bases')\n",
    "plt.ylabel('Magnitude of saliency values')\n",
    "plt.xticks(np.arange(len(sal)), list(sequences[sequence_index]));\n",
    "plt.title('Saliency map');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare prediction of individual sequence against model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_single_sequence = 230\n",
    "print('prediction: ')\n",
    "print(model.predict(X_test[predict_single_sequence:predict_single_sequence+1]))\n",
    "\n",
    "label_single_sequence = predict_single_sequence\n",
    "print('label: ')\n",
    "print(test_pos_labels[label_single_sequence:label_single_sequence+1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize convolution filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.get_weights()[0][:,0,0]\n",
    "# values of first filter\n",
    "#model.get_weights()[0][0].T\n",
    "\n",
    "print('shape of conv1d layer')\n",
    "print(np.shape(model.get_weights()[0]))\n",
    "plt.rcParams[\"figure.figsize\"] = (30,5)\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.heatmap(model.get_weights()[0][10],cmap='RdBu_r')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(model.get_weights()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#have a look at the filter\n",
    "convlayer = model.layers[0]\n",
    "weights = convlayer.get_weights()[0].squeeze()\n",
    "print('Convolution parameter shape: {}'.format(weights.shape))\n",
    "\n",
    "#convlayer2 = model.layers[2]\n",
    "#weights2 = convlayer2.get_weights()[0].squeeze()\n",
    "#print('Convolution parameter shape: {}'.format(weights2.shape))\n",
    "\n",
    "num2seq = ['A','C','G','T']\n",
    "\n",
    "#''.join([num2seq[np.argmax(weights[i,:])] for i in range(weights.shape[0])])\n",
    "#test_pred = ''.join([num2seq[np.argmax(weights[i,:])] for i in range(weights.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#argmax_conv_filter_list = []\n",
    "#for filter_index in range(41):\n",
    "#    argmax_conv_filter_list.append(''.join([num2seq[np.argmax(model.get_weights()[0][filter_index][:,x])] for x in range(41)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for fa_index in range(len(argmax_conv_filter_list)):\n",
    "#    print('>')\n",
    "#    print(argmax_conv_filter_list[fa_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/Users/tareen/Desktop/Desktop_Tests/logomaker3')\n",
    "import logomaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "learned_filter = pd.DataFrame(weights[:,:,1],columns = ['A','C','G','T'])\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "baseline_param_dict = {\n",
    "                          'baseline_width':1.0,\n",
    "                      }\n",
    "\n",
    "logo = logomaker.make_logo(\n",
    "                            dataframe=learned_filter,\n",
    "                            matrix_type='information',\n",
    "                            remove_flattened_characters=False,\n",
    "                            ytick_format='%0.1f',\n",
    "                            draw_now=True,\n",
    "                            figsize=[12,3],\n",
    "                            baseline_param_dict = baseline_param_dict,\n",
    "                            ylim=[0,0.04]\n",
    "                    )\n",
    "print(logo)\n",
    "plt.xlabel('Position',fontsize=12)\n",
    "plt.title('Convolution Filters visualized as information logo',fontsize=12)\n",
    "plt.ylabel('Information (bits)',fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('convolution_visualization2.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motif = np.array([[   0,   2, 104, 104,   1,   2, 103, 102,   0,   0,  99, 105,   0,   0, 100, 102,   5,   3],\n",
    "                  [   0,   0,   0,   0,   0,   0,   0,   0,   0,   2,   4,   0,   0,   2,   3,   0,   0,   3],\n",
    "                  [ 105, 103,   1,   1, 104, 102,   2,   3, 104, 103,   2,   0, 105, 103,   0,   2,  97,  97],\n",
    "                  [   0,   0,   0,   0,   0,   1,   0,   0,   1,   0,   0,   0,   0,   0,   2,   1,   3,   2]])\n",
    "\n",
    "motif_df = pd.DataFrame(motif)\n",
    "motif_df = motif_df.T\n",
    "motif_df.columns = ['A','C','G','T']\n",
    "motif_df\n",
    "\n",
    "logo_motif = logomaker.make_logo(\n",
    "                            dataframe=motif_df,\n",
    "                            #matrix_type='information',\n",
    "                            remove_flattened_characters=False,\n",
    "                            ytick_format='%0.1f',\n",
    "                            draw_now=True,\n",
    "                            figsize=[12,3],                        \n",
    "                            #ylim=[0,0.04]\n",
    "                    )\n",
    "print(logo)\n",
    "plt.xlabel('Position',fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,3)\n",
    "sns.set(font_scale = 1.75)\n",
    "sns.heatmap(logo.df[(logo.df > 0).all(1)].T,cmap='RdBu_r')\n",
    "plt.xlabel('Position',fontsize=20)\n",
    "plt.ylabel('Values',fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('convolution_filter_hm.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "#model.save('train_90k_test_5k_10_filters_1Convlayer.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "#del model  # deletes the existing model\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "#model = load_model('train_50k_test_2k_10_filters_1Convlayer.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.shape(weights2[:,0,:])\n",
    "#np.shape(weights[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "learned_filter2 = pd.DataFrame(weights2[:,9,:],columns = ['A','C','G','T'])\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "logo = logomaker.make_logo(\n",
    "                            dataframe=learned_filter2,\n",
    "                            matrix_type='information',\n",
    "                            remove_flattened_characters=False,\n",
    "                            ytick_format='%0.1f',\n",
    "                            draw_now=True,\n",
    "                            figsize=[7,3],\n",
    "                            ylim=[0,0.04]\n",
    "                    )\n",
    "print(logo)\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axs = plt.subplots(5,2,figsize=[12,10])\n",
    "learned_filter = pd.DataFrame(weights[:,:,0],columns = ['A','C','G','T'])\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "filter_index = 0\n",
    "for i in range(5):\n",
    "    for j in range(2):\n",
    "        learned_filter = pd.DataFrame(weights[:,:,filter_index],columns = ['A','C','G','T'])\n",
    "\n",
    "        \n",
    "        logo = logomaker.make_logo(\n",
    "                                    dataframe=learned_filter,\n",
    "                                    matrix_type='information',\n",
    "                                    remove_flattened_characters=False,\n",
    "                                    #ytick_format='%0.1f',\n",
    "                                    ylim=[0,0.05],\n",
    "                                    draw_now=False,\n",
    "                                )\n",
    "        axs[i,j].set_title(filter_index)\n",
    "        filter_index+=1\n",
    "        logo.draw(axs[i,j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_pos_tensor[0].T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "motif_learn_convnet.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
